from flask import Flask, render_template, request, jsonify, redirect, url_for, flash
from werkzeug.utils import secure_filename
import os
from datetime import datetime
import json

# å°å…¥æ‚¨ç¾æœ‰çš„æ ¸å¿ƒæ¨¡çµ„
from core.config import (
    get_available_model,
    generate_response,
    check_model_config,
    chatgpt_system_prompt,
    OpenAI_Model,
    openai_client
)

from core.search import (
    get_search,
    get_page_content,
    check_search_config
)

from core.file_processing import (
    process_uploaded_file,
    extract_course_info
)

from core.chunk import (
    num_tokens_from_string,
    chunk_texts
)

# å°å…¥æ‚¨çš„ä¸»è¦å‡½æ•¸
from gradio_app import (
    process_course_generation,
    extract_course_info_chunked,
    combine_extracted_info,
    generate_course_outline_with_rat
)

app = Flask(__name__)
app.secret_key = 'HSU, PAO-HUA'  # è«‹æ›´æ”¹ç‚ºå®‰å…¨çš„å¯†é‘°

# è¨­å®šæª”æ¡ˆä¸Šå‚³
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'txt', 'pdf', 'docx'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB é™åˆ¶

# ç¢ºä¿ä¸Šå‚³ç›®éŒ„å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# =============================================================================
# è·¯ç”±å®šç¾©
# =============================================================================

@app.context_processor
def inject_model_info():
    model_info = {
        'current_model': get_available_model().upper(),
        'openai_configured': bool(os.getenv('OPENAI_API_KEY')),
        'google_configured': bool(os.getenv('GOOGLE_API_KEY'))
    }
    return dict(model_info=model_info)


@app.route('/')
def index():
    """ä¸»é é¢"""
    model_info = {
        'current_model': get_available_model().upper(),
        'openai_configured': bool(os.getenv('OPENAI_API_KEY')),
        'google_configured': bool(os.getenv('GOOGLE_API_KEY'))
    }
    return render_template('index.html', model_info=model_info)

@app.route('/course')
def course_page():
    """èª²ç¨‹å¤§ç¶±ç”Ÿæˆé é¢"""
    return render_template('course.html')

@app.route('/api/generate_course', methods=['POST'])
def api_generate_course():
    """èª²ç¨‹å¤§ç¶±ç”Ÿæˆ API"""
    try:
        # ç²å–è¡¨å–®è³‡æ–™
        requirements = request.form.get('requirements', '').strip()
        enable_search = request.form.get('enable_search') == 'true'
        
        # è™•ç†æª”æ¡ˆä¸Šå‚³
        file_path = None
        if 'file' in request.files:
            file = request.files['file']
            if file and file.filename != '' and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(file_path)
        
        # æª¢æŸ¥è¼¸å…¥
        if not file_path and not requirements:
            return jsonify({
                'success': False,
                'error': 'Please upload a file or enter course requirements.'
            })
        
        # è™•ç†æª”æ¡ˆ
        course_info = ""
        if file_path:
            print(f"[INFO] Processing uploaded file: {file_path}")
            
            # å‰µå»ºè‡¨æ™‚æª”æ¡ˆç‰©ä»¶ä¾†æ¨¡æ“¬ Gradio çš„æª”æ¡ˆæ ¼å¼
            class TempFile:
                def __init__(self, path):
                    self.name = path
            
            temp_file = TempFile(file_path)
            file_content = process_uploaded_file(temp_file)
            
            if file_content and "éŒ¯èª¤" not in file_content:
                file_tokens = num_tokens_from_string(file_content)
                print(f"[INFO] File content tokens: {file_tokens}")
                
                if file_tokens > 4000:
                    print(f"[INFO] Large file, chunking...")
                    course_info = extract_course_info_chunked(file_content)
                else:
                    course_info = extract_course_info(file_content)
            else:
                return jsonify({
                    'success': False,
                    'error': f'File processing failed: {file_content}'
                })
            
            # æ¸…ç†ä¸Šå‚³çš„æª”æ¡ˆ
            try:
                os.remove(file_path)
            except:
                pass
        
        # å¦‚æœæ²’æœ‰æª”æ¡ˆï¼Œä½¿ç”¨ç”¨æˆ¶éœ€æ±‚
        if not course_info and requirements:
            course_info = requirements
        
        # ç”Ÿæˆèª²ç¨‹å¤§ç¶±
        print(f"[INFO] Starting course outline generation with RAT...")
        base_outline, final_outline = generate_course_outline_with_rat(
            course_info, 
            requirements, 
            search_enabled=enable_search
        )
        
        # ğŸ”¥ ç¢ºä¿ final_outline ä¸ç‚ºç©º
        if not final_outline or final_outline.strip() == '':
            final_outline = base_outline  # å‚™ç”¨æ–¹æ¡ˆ
        
        return jsonify({
            'success': True,
            'final_outline': final_outline,  # ğŸ”¥ åªè¿”å›æœ€çµ‚çµæœ
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        print(f"[ERROR] Course generation failed: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/system_status')
def api_system_status():
    """ç³»çµ±ç‹€æ…‹ API"""
    try:
        #å¾ core.config å°å…¥æ¨¡å‹é…ç½®
        try:
            from core.config import OpenAI_Model
            openai_model = OpenAI_Model
        except ImportError as e:
            print(f"[WARNING] Could not import from core.config: {e}")
            openai_model = 'gpt-3.5-turbo'  # é»˜èªå€¼
        
        # ç²å–ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹é¡å‹
        model_type = get_available_model()
        
        # æ ¹æ“šæ¨¡å‹é¡å‹ç¢ºå®šç•¶å‰ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬
        if model_type == 'openai':
            current_model_version = openai_model
        else:
            current_model_version = 'Unknown'
        
        status = {
            'model_type': model_type,
            'current_model_version': current_model_version,  # ğŸ”¥ ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹
            'openai_model': openai_model,  # ğŸ”¥ é…ç½®çš„ OpenAI æ¨¡å‹
            'openai_configured': bool(os.getenv('OPENAI_API_KEY')),
            'google_configured': bool(os.getenv('GOOGLE_API_KEY')),
            'google_cse_configured': bool(os.getenv('GOOGLE_CSE_ID')),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return jsonify(status)
        
    except Exception as e:
        print(f"[ERROR] System status failed: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/system')
def system_page():
    """ç³»çµ±è³‡è¨Šé é¢"""
    return render_template('system.html')

@app.route('/test')
def test_route():
    """æ¸¬è©¦è·¯ç”±"""
    return jsonify({'message': 'Flask is working!', 'timestamp': datetime.now().isoformat()})

# æ·»åŠ è·¯ç”±åˆ—è¡¨æŸ¥çœ‹å™¨
@app.route('/debug/routes')
def show_routes():
    """é¡¯ç¤ºæ‰€æœ‰å¯ç”¨è·¯ç”±"""
    routes = []
    for rule in app.url_map.iter_rules():
        methods = ', '.join(rule.methods - {'HEAD', 'OPTIONS'})
        routes.append(f"{rule.rule} [{methods}] -> {rule.endpoint}")
    return '<br>'.join(routes)


# =============================================================================
# éŒ¯èª¤è™•ç†
# =============================================================================

@app.errorhandler(404)
def not_found_error(error):
    return render_template('404.html'), 404

@app.errorhandler(500)
def internal_error(error):
    return render_template('500.html'), 500

@app.errorhandler(413)
def too_large(e):
    flash('File is too large. Maximum size is 16MB.', 'error')
    return redirect(url_for('course_page'))

# =============================================================================
# æ‡‰ç”¨åˆå§‹åŒ–å’Œå•Ÿå‹•
# =============================================================================

def initialize_app():
    """åˆå§‹åŒ–æ‡‰ç”¨"""
    print(f"{datetime.now()} [INFO] Initializing Flask RAT application...")
    print(f"{datetime.now()} [INFO] Checking model config...")
    check_model_config()
    print(f"{datetime.now()} [INFO] Checking Google Search API key...")
    check_search_config()
    print(f"{datetime.now()} [INFO] Flask app initialized successfully")

if __name__ == '__main__':
    initialize_app()
    app.run(
        host='0.0.0.0',
        port=7860,
        debug=True
    )